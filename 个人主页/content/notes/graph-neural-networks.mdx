---
title: "Introduction to Graph Neural Networks"
date: "2025-12-15"
description: "An overview of graph neural networks, including GCN, GAT, and their applications in molecular property prediction."
tags: ["Graph Neural Networks", "Deep Learning", "GCN", "GAT"]
category: "Deep Learning"
---

# Introduction to Graph Neural Networks

Graph Neural Networks (GNNs) are a class of deep learning methods designed to perform inference on data structured as graphs.

## Why Graphs?

Many real-world problems involve data with complex relationships:
- Social networks
- Molecular structures
- Citation networks
- Knowledge graphs

## Message Passing Framework

Most GNNs follow the message passing paradigm:

$$
h_v^{(l+1)} = \text{UPDATE}\left(h_v^{(l)}, \text{AGGREGATE}\left(\{h_u^{(l)} : u \in \mathcal{N}(v)\}\right)\right)
$$

Where:
- $h_v^{(l)}$ is the feature of node $v$ at layer $l$
- $\mathcal{N}(v)$ is the neighborhood of node $v$

## Graph Convolutional Network (GCN)

The GCN layer can be written as:

$$
H^{(l+1)} = \sigma\left(\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}H^{(l)}W^{(l)}\right)
$$

## Code Example

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv

class GCN(nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels):
        super().__init__()
        self.conv1 = GCNConv(in_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, out_channels)
    
    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.conv2(x, edge_index)
        return x
```

## Applications

1. **Node Classification**: Predicting labels for nodes
2. **Link Prediction**: Predicting missing edges
3. **Graph Classification**: Classifying entire graphs
